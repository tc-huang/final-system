{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colab\n",
    "# !pip install spacy_stanza\n",
    "# !pip install ckip_transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import pathlib\n",
    "import sys\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Spacy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_pipeline_parent_path = pathlib.Path.cwd().parent.parent.parent.parent\n",
    "sys.path.append(str(spacy_pipeline_parent_path))\n",
    "\n",
    "from spacy_pipeline import pipeline_setup\n",
    "from spacy_pipeline import opinion_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"opinion_v0\": {\n",
    "        \"version\": \"opinion_v0\",\n",
    "        \"pattern\": [\n",
    "            {\n",
    "                \"RIGHT_ID\": \"OPINION_OPR_found_root\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"TAG\": {\n",
    "                        \"IN\": [\"VE\"]\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"OPINION_OPR_found_root\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": \"OPINION_SRC_found_root\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": {\n",
    "                        \"IN\": [\"nsubj\"]\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"OPINION_OPR_found_root\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": \"OPINION_SEG_found_root\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": {\n",
    "                        \"IN\": [\"ccomp\"]#, \"parataxis\"]\n",
    "                    },\n",
    "                    # \"POS\": {\n",
    "                    #         \"IN\": [\"VERB\", \"NOUN\", \"ADJ\"]\n",
    "                    # }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline_setup.get_opinion_pipeline(methods['opinion_v0'])\n",
    "vocab = pipeline.vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_work_flow(all_docs, spacy_pipeline, n_process=1):\n",
    "    \n",
    "    # try:\n",
    "    with tqdm(total=len(all_docs)) as pbar:\n",
    "        \n",
    "        for paragraphs in all_docs:\n",
    "                \n",
    "            for i, doc in enumerate(spacy_pipeline.pipe(paragraphs, n_process=n_process)):\n",
    "                pass\n",
    "            pbar.update(1)\n",
    "    return all_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = str(pathlib.Path.cwd().parent)\n",
    "pickle_file = 'label_news_200_docs_stanza.pkl'\n",
    "\n",
    "with open(pickle_dir + '/' + pickle_file, 'rb') as f:\n",
    "    bytes_data = pickle.load(f)\n",
    "    all_docs_dev = [[Doc(vocab).from_bytes(doc_bytes) for doc_bytes in docs] for docs in bytes_data]\n",
    "\n",
    "all_docs_dev = run_work_flow(all_docs_dev, pipeline, n_process=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all_docs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = str(pathlib.Path.cwd().parent)\n",
    "pickle_file = 'label_news_50_test_docs_stanza.pkl'\n",
    "\n",
    "with open(pickle_dir + '/' + pickle_file, 'rb') as f:\n",
    "    bytes_data = pickle.load(f)\n",
    "    all_docs_test = [[Doc(vocab).from_bytes(doc_bytes) for doc_bytes in docs] for docs in bytes_data]\n",
    "\n",
    "all_docs_test = run_work_flow(all_docs_test, pipeline, n_process=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# span level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def get_recall(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def get_f_score(precision, recall, beta=1):\n",
    "    return (1 + beta**2) * precision * recall / (beta**2 * precision + recall)\n",
    "\n",
    "label_match_dict = {\n",
    "    \"OPINION_SRC\": \"OPINION_SRC_found\",\n",
    "    \"OPINION_OPR\": \"OPINION_OPR_found\",\n",
    "    \"OPINION_SEG\": \"OPINION_SEG_found\" \n",
    "}\n",
    "\n",
    "def delete_around_punt_check_span(label_span, match_span):\n",
    "    puct_list = ['，', '。', '「', '」', ' ', '！', '？', ';', ':', \"'\", '\"', '‘', '“', '『', '』', '、', '（', '）']\n",
    "    \n",
    "    while label_span.text[0] in puct_list:\n",
    "        label_span = label_span[1:]\n",
    "\n",
    "    while label_span.text[-1] in puct_list:\n",
    "        label_span = label_span[:-1] \n",
    "    \n",
    "    while match_span.text[0] in puct_list:\n",
    "        match_span = match_span[1:]\n",
    "\n",
    "    while match_span.text[-1] in puct_list:\n",
    "        match_span = match_span[:-1]\n",
    "\n",
    "    \n",
    "    if label_span.start == match_span.start and label_span.end == match_span.end:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def interval_check_span(label_span, match_span):\n",
    "    if label_span.start <= match_span.start and label_span.end >= match_span.end:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def tolerance_check_span(label_span, match_span, tolerance=1):\n",
    "    if abs(label_span.start - match_span.start) <= tolerance and label_span.end == match_span.end:\n",
    "        return True\n",
    "    if label_span.start == match_span.start and abs(label_span.end - match_span.end) <= tolerance:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_eval(all_docs, method):\n",
    "    \n",
    "    counter = {\n",
    "        'OPINION_OPR_FP': 0,\n",
    "        'OPINION_OPR_FN': 0,\n",
    "        'OPINION_OPR_TP': 0,\n",
    "\n",
    "        'OPINION_SRC_FP': 0,\n",
    "        'OPINION_SRC_FN': 0,\n",
    "        'OPINION_SRC_TP': 0,\n",
    "        \n",
    "        'OPINION_SEG_FP': 0,\n",
    "        'OPINION_SEG_FN': 0,\n",
    "        'OPINION_SEG_TP': 0,\n",
    "    }\n",
    "\n",
    "    for docs in all_docs:\n",
    "        for doc in docs:\n",
    "\n",
    "            spans = {\n",
    "                'OPINION_SRC_TP': [],\n",
    "                'OPINION_OPR_TP': [],\n",
    "                'OPINION_SEG_TP': [],\n",
    "\n",
    "                'OPINION_SRC_FP': [],\n",
    "                'OPINION_OPR_FP': [],\n",
    "                'OPINION_SEG_FP': [],\n",
    "\n",
    "                'OPINION_SRC_FN': [],\n",
    "                'OPINION_OPR_FN': [],\n",
    "                'OPINION_SEG_FN': [],\n",
    "            }\n",
    "            \n",
    "            if 'opinion_found' in doc.spans and 'opinion_label' in doc.spans:\n",
    "                for found_span in doc.spans['opinion_found']:\n",
    "                    found_match = False\n",
    "                    for label_span in doc.spans['opinion_label']:\n",
    "                        if method(label_span, found_span) and found_span.label_ == label_match_dict[label_span.label_]:\n",
    "                            spans[f\"{label_span.label_}_TP\"].append(label_span)\n",
    "                            found_match = True\n",
    "                            break\n",
    "                    if not found_match:\n",
    "                        spans[f\"{found_span.label_[:11]}_FP\"].append(found_span)\n",
    "                \n",
    "                for label_span in doc.spans['opinion_label']:\n",
    "                    if label_span not in spans[f\"{label_span.label_}_TP\"]:\n",
    "                        spans[f\"{label_span.label_}_FN\"].append(label_span)\n",
    "\n",
    "            elif 'opinion_found' in doc.spans:\n",
    "                for found_span in doc.spans['opinion_found']:\n",
    "                    spans[f\"{found_span.label_[:11]}_FP\"].append(found_span)\n",
    "\n",
    "            elif 'opinion_label' in doc.spans:\n",
    "                for label_span in doc.spans['opinion_label']:\n",
    "                    spans[f\"{label_span.label_}_FN\"].append(label_span)\n",
    "\n",
    "            for key in counter.keys():\n",
    "                counter[key] += len(spans[key])\n",
    "\n",
    "    return {\n",
    "        'OPINION_SRC': {\n",
    "            'precision': get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']), get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN'])),\n",
    "        },\n",
    "        'OPINION_OPR': {\n",
    "            'precision': get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']),\n",
    "            'recall': get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']), get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN'])),\n",
    "        },\n",
    "        'OPINION_SEG': {\n",
    "            'precision': get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']), get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']))\n",
    "        },\n",
    "        'counter': counter\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eval(all_docs_dev, delete_around_punt_check_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eval(all_docs_test, delete_around_punt_check_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_eval(all_docs_dev, delete_around_punt_check_span)\n",
    "# new_eval(all_docs, interval_check)\n",
    "# new_eval(all_docs, tolerance_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_eval(all_docs_test, delete_around_punt_check_span)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# token level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_token_level(all_docs):\n",
    "\n",
    "    counter = {\n",
    "        'OPINION_SRC_FP': 0,\n",
    "        'OPINION_OPR_FP': 0,\n",
    "        'OPINION_SEG_FP': 0,\n",
    "\n",
    "        'OPINION_SRC_FN': 0,\n",
    "        'OPINION_OPR_FN': 0,\n",
    "        'OPINION_SEG_FN': 0,\n",
    "        \n",
    "        'OPINION_SRC_TP': 0,\n",
    "        'OPINION_OPR_TP': 0,\n",
    "        'OPINION_SEG_TP': 0,\n",
    "    }\n",
    "\n",
    "    for docs in all_docs:\n",
    "        for doc in docs:\n",
    "            \n",
    "            if 'opinion_found' in doc.spans and 'opinion_label' in doc.spans:\n",
    "                for token in doc:\n",
    "                    if token._.found_type == \"OPINION_SRC_found\":\n",
    "                        if \"OPINION_SRC\" in token._.label_type:\n",
    "                            counter['OPINION_SRC_TP'] += 1\n",
    "                        else:\n",
    "                            counter['OPINION_SRC_FP'] += 1\n",
    "                    elif token._.found_type == \"OPINION_OPR_found\":\n",
    "                        if \"OPINION_OPR\" in token._.label_type:\n",
    "                            counter['OPINION_OPR_TP'] += 1\n",
    "                        else:\n",
    "                            counter['OPINION_OPR_FP'] += 1\n",
    "                    elif token._.found_type == \"OPINION_SEG_found\":\n",
    "                        if \"OPINION_SEG\" in token._.label_type:\n",
    "                            counter['OPINION_SEG_TP'] += 1\n",
    "                        else:\n",
    "                            counter['OPINION_SEG_FP'] += 1\n",
    "                \n",
    "                for token in doc:\n",
    "                    if \"OPINION_SRC\" in token._.label_type and token._.found_type != \"OPINION_SRC_found\":\n",
    "                        counter['OPINION_SRC_FN'] += 1\n",
    "                    elif \"OPINION_OPR\" in token._.label_type and token._.found_type != \"OPINION_OPR_found\":\n",
    "                        counter['OPINION_OPR_FN'] += 1\n",
    "                    elif \"OPINION_SEG\" in token._.label_type and token._.found_type != \"OPINION_SEG_found\":\n",
    "                        counter['OPINION_SEG_FN'] += 1\n",
    "\n",
    "    return {\n",
    "        'OPINION_SRC': {\n",
    "            'precision': get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']), get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN'])),\n",
    "        },\n",
    "        'OPINION_OPR': {\n",
    "            'precision': get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']),\n",
    "            'recall': get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']), get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN'])),\n",
    "        },\n",
    "        'OPINION_SEG': {\n",
    "            'precision': get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']), get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']))\n",
    "        },\n",
    "        'counter': counter\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_token_level(all_docs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_token_level(all_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_token_level(all_docs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_token_level(all_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_dev[0][0].ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in all_docs_dev[0][0].ents:\n",
    "    print(ent, ent.label_, ent.start, ent.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = all_docs_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_list = []\n",
    "\n",
    "for doc in docs:\n",
    "    ent_list = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    ent_list_list.append(ent_list)\n",
    "\n",
    "ent_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"中國國民黨主席朱立倫今天上午陪國民黨桃園市長候選人張善政車隊掃街時表示，他對張善政有100％信心，能力、學歷與經歷都是最好的桃園市長人選。\"\n",
    "s2 = \"對於傳出衛福部高層要求官員路過陳時中的選前之夜幫忙衝人氣，蔣萬安表示，台北未來能夠站上國際舞台、跟國際一流城市並駕齊驅，相互競爭，才是他真正關心的事情。\"\n",
    "s3 = \"陳時中在介紹政策口袋書時開玩笑說：「這可以保存30年沒問題，所以要的人很多。」保存30年的哏是前陣子藍白陣營不斷抹黑武漢肺炎（新型冠狀病毒病，COVID-19）疫苗採購價格的公文要「封存」30年，但實際上是要讓公文「保存」30年，讓之後有需要查閱時可獲取。疫苗採購的保密年限不同品牌有不同時間，例如國產高端疫苗要5年（已由高端公司自行公布）、Novavax疫苗要7年、BNT疫苗要10年，屆期馬上可以解密。\"\n",
    "s4 = \"林耕仁並承諾老人年金一定會續發，而且65歲以上的長輩，健保費由政府來承擔，更會研擬放寬發放的年限、加碼重陽敬老金從2000到3000，還有擴大敬老卡的使用範圍，並且研擬將額度從600提升到1200。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pipeline(s1)\n",
    "displacy.render(doc, style=\"dep\", options={'fine_grained':\"True\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pipeline(s1)\n",
    "print()\n",
    "displacy.render(doc, style=\"span\", options={'spans_key':\"opinion_found[1]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [\"「炎上 王世堅」上周末登場，前台南市議員謝龍介也應邀出席，沒想到博恩現場大爆謝龍介兒子持毒，大酸「這個爸爸教育多失敗啊！兒子連藏個毒品都不會」，讓謝龍介當場臉超臭。不少網友看完紛紛嚇傻表示「還真的不知道有這事。」對此，謝龍介今（12日）受訪首度證實博恩「脫稿演出」，並親吐「當場臉垮」的內幕！\",\n",
    "            \"根據《中時新聞網》採訪，謝龍介透露《炎上》的腳本都是用國語寫的，但我用台語跟觀眾互動會比較溜，他表示現場觀眾都是買票進場，所以先前從中午一直彩排到晚上八點，要做一些準備，這樣演出才會比較自然，跟觀眾的互動才會比較好。不過針對博恩挖出他兒子2013年吸毒事件，讓他當場臉垮掉，對此謝龍介首度證實「事先的稿子完全沒有這段，他們也是脫稿演出，當下有一點驚訝，不過事情過去了就還好，不會影響我在現場的演出，之後如果有機會可能還會再上炎上。」\",\n",
    "            \"謝龍介上週末出席「炎上 王世堅」，沒想到博恩提到相當敏感的「兒子持K他命」一事，「蠻羨慕你台語講很好，吸毒台語怎麼講？『恁囝嗎？』這個爸爸教育多失敗，連藏個毒品都不會，有這麼難嗎？你不是整天玩布袋戲，你兒子怎麼不知道往X眼裡塞。」許多網友看完後紛紛嚇傻表示「現場看有看到第一次提到兒子持毒事件時，謝龍介議員臉超臭！有心驚到，後面再提表情稍微笑笑的」、「提到兒子時，謝龍介的臉直接垮」。 \",\n",
    "            \"★ 三立新聞網提醒您：\",\n",
    "            \"　莫逞一時樂，遺害百年身！　拒絕毒品　珍惜生命　健康無價　不容毒噬\"]\n",
    "\n",
    "doc2 = [\n",
    "                \"副總統賴清德今天晚間出席台北場「向黨員報告」發表會，他強調，民進黨是第一個土生土長的本土政權，存在目的只有一個，就是為台灣打拚。現在是民進黨新使命的開始，就是守護台灣，未來選舉，我們絕對是直接面對共產黨，所以一定要團結，得到台灣社會絕大多數的支持，力量才會夠。\",\n",
    "            \"賴清德今晚在劍潭青年活動中心1樓集賢廳舉行台北市「向黨員報告-政見發表會」，立委吳思瑤、何志偉、高嘉瑜、吳玉琴及多位台北市議員到場支持。\",\n",
    "            \"由於何志偉和高嘉瑜近來對民進黨多所批評，高嘉瑜一進場就被支持者大噓「背骨」「下台」，何志偉致詞時也不停被台下的喊叫聲打斷，大嗆「不要官腔官調」「為什麼叫蘇貞昌下台？」何則回應「我沒有叫蘇貞昌下台」。\",\n",
    "            \"也有支持者要兩人「加油」，還趨前要求握手，賴清德進場時，被問到如何看待高嘉瑜被嗆聲、是否會幫她抱屈？賴清德面對提問並未回應。\",\n",
    "            \"賴清德致詞時表示，雖然大家都不願意看到九合一敗選結果，但既然結果出來就要接受，從失敗中找到原因，重振旗鼓、重新出發。他從新北走到全台各地再到台北市，發現民進黨支持者的力量，「今天如果不是想要繼續和民進黨一起打拚，守護台灣，大家不會在這裡」。\",\n",
    "            \"他強調，雖說「敗軍之將不可言勇」，但也有句俗語說「不以勝敗論英雄」，雖然參選台北市長失敗的陳時中不在現場，但他要求現場民眾報以掌聲，肯定陳時中的表現。\",\n",
    "            \"現場有很多資深黨員，也有年輕黨員，賴清德指出，這代表無論是哪個年代的人，對民進黨一樣支持，他以當年創黨時的艱辛為例，強調當時的創黨黨員，很多都是抱著犧牲奉獻的決心，來反抗當時獨裁的國民黨，民進黨是台灣第一個土生土長的本土政權，有它必要的使命，存在目的只有一個，就是為台灣打拚。\",\n",
    "            \"他強調，如果沒有這種決心和覺悟的人，請他早早離開，我們的意志就是為台灣打拚，沒有其他第二句話。民進黨過去多年，結合台灣社會力量，打破黨禁、報禁，追求百分之百民主自由，推動國會全面改選、總統直選，帶動台灣民主進步和國家發展，民進黨支持者講話敢大聲，大家也都願意犧牲。\",\n",
    "            \"賴清德要求大家，現在應該要有這樣的精神，重新喚回社會的感動和支持，過去為台灣民主很多人被關甚至犧生性命，為民主對抗獨裁的國民黨，現在是新民主的起點，也是新時代、新使命的開始，這個使命就是守護台灣。\",\n",
    "            \"他說，看看過去的選舉歷史，2000年陳水扁當選，是因為國民黨腐敗，2004年又當選，是因為經過4年執政，認真打拚才贏了一些，2008年民進黨輸，是因為力量不夠，對抗的是國民黨加上共產黨，2012年仍然力量不夠，2016年能贏，是因為國民黨站前面，共產黨站後面。\",\n",
    "            \"賴清德強調，未來我們要面對的，要守護台灣，絕對是直接面對共產黨。所以我們一定要團結，得到台灣社會絕大多數的支持，如果能如此，我們的力量就一定夠，如果不團結，力量一定不夠。\",\n",
    "            \"他說，台灣的力量「取之不盡，用之不竭」，只要有使命，有力量，方法正確，他相信一定能找回社會的感動，呼籲大家共同打拚，成功守護台灣，為守護台灣共同努力。\"\n",
    "]\n",
    "\n",
    "doc3 = [\n",
    "                \"〔記者鍾麗華／台北報導〕行政院長蘇貞昌今天（12日）接見立陶宛國會國安及國防事務議員訪團，他致詞時表示，中國的威權擴張毫無道理且蠻橫，台灣應與立陶宛加強合作，一起努力對抗集權擴張行為。\",\n",
    "            \"蘇揆強調，立陶宛與台灣都在威權擴張侵略的最前線，兩國同樣堅持自由、民主，有相同的價值。台灣受到中國軍事騷擾和假訊息滲透，訪團成員、立陶宛國會友台小組副主席莎卡琳恩因關切新疆人權問題，被中國制裁，台灣與立陶宛應加強合作對抗蠻橫的極權擴張行為。\",\n",
    "            \"蘇揆指出，威權擴張侵略時常違反世界期待，如俄羅斯侵略烏克蘭，透過武力遂行擴張目的，除讓民眾變成難民，也影響整個世界的經濟活動；而中國對台灣的軍事騷擾及各種假訊息滲透，也都是違背世界期待、侵擾區域和平。\",\n",
    "            \"卡斯楚那斯表示，民主國家正努力對抗威權擴張，未來可能會有衝突，這次與台灣官員、智庫交流有個共識，就是國防不能只靠軍隊，應該要靠社會一起執行全民國防，他也願意分享立陶宛的經驗。立陶宛很有韌性，面對中國壓力還是存活，未來希望扮演歐洲國家的典範，與台灣成功合作，而這次訪台在投資、技術合作方面都有好消息，希望未來可以進一步落實。\",\n",
    "            \"立陶宛國會友台小組副主席莎卡琳恩指出，台灣與立陶宛都距離敵人很近，這同時是威脅也是優勢，那就是可以近距離觀察敵人，越來越多人理解到中國的危險，立陶宛也在歐洲努力倡導這個概念，如同俄羅斯侵略烏克蘭一樣，如果台灣被入侵，全世界都會受到影響，應該全力避免。\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_reverseiterator at 0x13867e910>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_list(docs, paragraph_index):\n",
    "    ent_list_list = []\n",
    "    for doc in docs:\n",
    "        ent_list = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        ent_list.reverse()\n",
    "        ent_list_list.append(ent_list)\n",
    "    same_paragraph = ent_list_list[paragraph_index] \n",
    "    ent_list_list = ent_list_list[:paragraph_index] \n",
    "    ent_list_list.reverse()\n",
    "    return same_paragraph, [i for j in ent_list_list for i in j]\n",
    "\n",
    "def check_SRC_type(span):\n",
    "    if len(span) == 1:\n",
    "        token = span[0]\n",
    "        if len(token) == 1:\n",
    "            if token.pos_ == \"PRON\":\n",
    "                return (token.pos_, token.text) # 他\n",
    "            elif token.pos_ == \"PROPN\":\n",
    "                return (token.pos_, token.text)# 張\n",
    "        # else:\n",
    "        #     if token.pos_ == \"NOUN\":\n",
    "        #         return True # 官員 總統\n",
    "    \n",
    "    elif len(span) == 2:\n",
    "        token1, token2 = span[0], span[1]\n",
    "        if len(token1) == 1 and len(token2) == 2:\n",
    "            if token1.pos_ == \"PROPN\" and token2.pos_ == \"NOUN\":\n",
    "                return (token1.pos_, token1.text) # 蔡總統 盧市長\n",
    "        \n",
    "        # if token1.pos_ == \"NOUN\" and token2.pos_ == \"NOUN\":\n",
    "        #     return True # 媽媽市長 縣黨部\n",
    "    \n",
    "    elif len(span) == 3:\n",
    "        token1, token2, token3 = span[0], span[1], span[2]\n",
    "        if len(token1) == 1 and len(token2) == 1 and len(token3) == 2:\n",
    "            if token1.pos_ == \"PROPN\" and token2.pos_ == \"PART\" and token3.pos_ == \"NOUN\":\n",
    "                return (token1.pos_, token1.text) # 賴副總統\n",
    "    \n",
    "    # if len(span) >= 2:\n",
    "    #     if span[0].pos_ == \"DET\" and all([\"NOUN\" in token.pos_ for token in span[1:]]):\n",
    "    #         return \"DET\" # 該綠營人士 這名黨政人士 該人士 該立委\n",
    "        \n",
    "    \n",
    "        \n",
    "        # elif span[0].pos_ == \"NUM\" and all([\"NOUN\" in token.pos_ for token in span[1:]]):\n",
    "        #     return True # 3位監委 2位監委\n",
    "    return None\n",
    "\n",
    "def find_pronoun_resolution(docs, pragraph_index, span):\n",
    "    span_type= check_SRC_type(span)\n",
    "    print(\"span_type\", span_type)\n",
    "    if span_type != None:\n",
    "        print(\"span_type[0]\", span_type[0], span_type[0] == \"PRON\")\n",
    "        if span_type[0] == \"PRON\":\n",
    "            names_same_paragraph, names_before = get_name_list(docs, pragraph_index)\n",
    "            print(\"here\")\n",
    "            print(\"PRON\", names_same_paragraph, names_before)\n",
    "            if len(names_same_paragraph) != 0:\n",
    "                for name in names_same_paragraph:\n",
    "                    if name.start < span.start:\n",
    "                        return name\n",
    "            if len(names_before) > 0:\n",
    "                return names_before[0]\n",
    "            return None\n",
    "        \n",
    "        if span_type[0] == \"PROPN\":\n",
    "            names_same_paragraph, names_before = get_name_list(docs, pragraph_index, span)\n",
    "            print(\"PRON\", names_same_paragraph, names_before)\n",
    "            if len(names_same_paragraph) != 0:\n",
    "                for name in names_same_paragraph:\n",
    "                    if name.start < span.start and span_type[1] in name.text:\n",
    "                        return name\n",
    "            if len(names_before) > 0:\n",
    "                for name in names_before:\n",
    "                    if name.start < span.start and span_type[1] in name.text:\n",
    "                        return name\n",
    "            return None\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span_type ('PRON', '他')\n",
      "span_type[0] PRON True\n",
      "here\n",
      "PRON [博恩, 謝龍介今, 謝龍介, 大爆謝龍介, 博恩, 謝龍介, 王世堅] []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "大爆謝龍介"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_pronoun_resolution(doc1, paragraph_index, target_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[「炎上 王世堅」上周末登場，前台南市議員謝龍介也應邀出席，沒想到博恩現場大爆謝龍介兒子持毒，大酸「這個爸爸教育多失敗啊！兒子連藏個毒品都不會」，讓謝龍介當場臉超臭。不少網友看完紛紛嚇傻表示「還真的不知道有這事。」對此，謝龍介今（12日）受訪首度證實博恩「脫稿演出」，並親吐「當場臉垮」的內幕！,\n",
       " 根據《中時新聞網》採訪，謝龍介透露《炎上》的腳本都是用國語寫的，但我用台語跟觀眾互動會比較溜，他表示現場觀眾都是買票進場，所以先前從中午一直彩排到晚上八點，要做一些準備，這樣演出才會比較自然，跟觀眾的互動才會比較好。不過針對博恩挖出他兒子2013年吸毒事件，讓他當場臉垮掉，對此謝龍介首度證實「事先的稿子完全沒有這段，他們也是脫稿演出，當下有一點驚訝，不過事情過去了就還好，不會影響我在現場的演出，之後如果有機會可能還會再上炎上。」,\n",
       " 謝龍介上週末出席「炎上 王世堅」，沒想到博恩提到相當敏感的「兒子持K他命」一事，「蠻羨慕你台語講很好，吸毒台語怎麼講？『恁囝嗎？』這個爸爸教育多失敗，連藏個毒品都不會，有這麼難嗎？你不是整天玩布袋戲，你兒子怎麼不知道往X眼裡塞。」許多網友看完後紛紛嚇傻表示「現場看有看到第一次提到兒子持毒事件時，謝龍介議員臉超臭！有心驚到，後面再提表情稍微笑笑的」、「提到兒子時，謝龍介的臉直接垮」。 ,\n",
       " ★ 三立新聞網提醒您：,\n",
       " 　莫逞一時樂，遺害百年身！　拒絕毒品　珍惜生命　健康無價　不容毒噬]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "謝龍介\n",
      "博恩\n",
      "謝龍介\n",
      "博恩\n",
      "謝龍介今\n",
      "謝龍介\n",
      "大爆謝龍介\n",
      "博恩\n",
      "謝龍介\n",
      "王世堅\n"
     ]
    }
   ],
   "source": [
    "for doc in doc2:\n",
    "    for s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([謝龍介, 謝龍介, 博恩, 王世堅, 謝龍介上], [謝龍介, 博恩, 謝龍介, 博恩, 謝龍介今, 謝龍介, 大爆謝龍介, 博恩, 謝龍介, 王世堅])\n"
     ]
    }
   ],
   "source": [
    "print(get_name_list(doc1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = get_name_list(doc1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPN']\n",
      "['PROPN']\n",
      "['PROPN']\n",
      "['PROPN']\n",
      "['PROPN', 'NOUN']\n",
      "['PROPN']\n",
      "['VERB']\n",
      "['PROPN']\n",
      "['PROPN']\n",
      "['PART', 'PROPN']\n"
     ]
    }
   ],
   "source": [
    "for i in l[1]:\n",
    "    print([j.pos_ for j in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[謝龍介, 謝龍介, 博恩, 王世堅, 謝龍介上]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[「炎上 王世堅」上周末登場，前台南市議員謝龍介也應邀出席，沒想到博恩現場大爆謝龍介兒子持毒，大酸「這個爸爸教育多失敗啊！兒子連藏個毒品都不會」，讓謝龍介當場臉超臭。不少網友看完紛紛嚇傻表示「還真的不知道有這事。」對此，謝龍介今（12日）受訪首度證實博恩「脫稿演出」，並親吐「當場臉垮」的內幕！,\n",
       " 根據《中時新聞網》採訪，謝龍介透露《炎上》的腳本都是用國語寫的，但我用台語跟觀眾互動會比較溜，他表示現場觀眾都是買票進場，所以先前從中午一直彩排到晚上八點，要做一些準備，這樣演出才會比較自然，跟觀眾的互動才會比較好。不過針對博恩挖出他兒子2013年吸毒事件，讓他當場臉垮掉，對此謝龍介首度證實「事先的稿子完全沒有這段，他們也是脫稿演出，當下有一點驚訝，不過事情過去了就還好，不會影響我在現場的演出，之後如果有機會可能還會再上炎上。」,\n",
       " 謝龍介上週末出席「炎上 王世堅」，沒想到博恩提到相當敏感的「兒子持K他命」一事，「蠻羨慕你台語講很好，吸毒台語怎麼講？『恁囝嗎？』這個爸爸教育多失敗，連藏個毒品都不會，有這麼難嗎？你不是整天玩布袋戲，你兒子怎麼不知道往X眼裡塞。」許多網友看完後紛紛嚇傻表示「現場看有看到第一次提到兒子持毒事件時，謝龍介議員臉超臭！有心驚到，後面再提表情稍微笑笑的」、「提到兒子時，謝龍介的臉直接垮」。 ,\n",
       " ★ 三立新聞網提醒您：,\n",
       " 　莫逞一時樂，遺害百年身！　拒絕毒品　珍惜生命　健康無價　不容毒噬]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[謝龍介, 博恩, 謝龍介, 博恩, 謝龍介今, 謝龍介, 大爆謝龍介, 博恩, 謝龍介, 王世堅]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m([(i\u001b[39m.\u001b[39mstart, i\u001b[39m.\u001b[39mend)\u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m get_name_list(doc1, \u001b[39m5\u001b[39;49m)])\n",
      "Cell \u001b[0;32mIn[75], line 7\u001b[0m, in \u001b[0;36mget_name_list\u001b[0;34m(docs, paragraph_index)\u001b[0m\n\u001b[1;32m      5\u001b[0m     ent_list\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m      6\u001b[0m     ent_list_list\u001b[39m.\u001b[39mappend(ent_list)\n\u001b[0;32m----> 7\u001b[0m same_paragraph \u001b[39m=\u001b[39m ent_list_list[paragraph_index] \n\u001b[1;32m      8\u001b[0m ent_list_list \u001b[39m=\u001b[39m ent_list_list[:paragraph_index] \n\u001b[1;32m      9\u001b[0m ent_list_list\u001b[39m.\u001b[39mreverse()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print([(i.start, i.end)for i in get_name_list(doc1, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 18:55:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6ed05e7f094381bdb59c7525fecc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 18:55:27 INFO: Loading these models for language: zh-hant (Traditional_Chinese):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-03-28 18:55:27 INFO: Using device: cpu\n",
      "2023-03-28 18:55:27 INFO: Loading: tokenize\n",
      "2023-03-28 18:55:27 INFO: Loading: pos\n",
      "2023-03-28 18:55:28 INFO: Loading: lemma\n",
      "2023-03-28 18:55:28 INFO: Loading: depparse\n",
      "2023-03-28 18:55:28 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ckip_pos', 'ckip_ner', 'opinion_matcher']\n",
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns   Requires   Scores   Retokenizes\n",
      "-   ---------------   -------   --------   ------   -----------\n",
      "0   ckip_pos                                        False      \n",
      "                                                               \n",
      "1   ckip_ner                                        False      \n",
      "                                                               \n",
      "2   opinion_matcher                                 False      \n",
      "\n",
      "\u001b[38;5;2m✔ No problems found.\u001b[0m\n",
      "{'summary': {'ckip_pos': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}, 'ckip_ner': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}, 'opinion_matcher': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}}, 'problems': {'ckip_pos': [], 'ckip_ner': [], 'opinion_matcher': []}, 'attrs': {}}\n"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline_setup.get_opinion_pipeline(methods['opinion_v0'])\n",
    "vocab = pipeline.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [ doc for doc in pipeline.pipe(doc1)]\n",
    "doc2 = [ doc for doc in pipeline.pipe(doc2)]\n",
    "doc3 = [ doc for doc in pipeline.pipe(doc3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(王世堅, 'PERSON'), (謝龍介, 'PERSON'), (博恩, 'PERSON'), (大爆謝龍介, 'PERSON'), (謝龍介, 'PERSON'), (謝龍介今, 'PERSON'), (博恩, 'PERSON')]\n",
      "[(謝龍介, 'PERSON'), (博恩, 'PERSON'), (謝龍介, 'PERSON')]\n",
      "[(謝龍介上, 'PERSON'), (王世堅, 'PERSON'), (博恩, 'PERSON'), (謝龍介, 'PERSON'), (謝龍介, 'PERSON')]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for doc in doc1:\n",
    "    print([(ent, ent.label_) for ent in doc.ents if ent.label_ == 'PERSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, None, None)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_span = None\n",
    "target_doc = None\n",
    "def run():\n",
    "    for paragraph_index, doc in enumerate(doc3):\n",
    "        if 'opinion_found' in doc.spans:\n",
    "            for i, span in enumerate(doc.spans['opinion_found']):\n",
    "                if span.text == \"他\":\n",
    "                    target_span = span\n",
    "                    target_doc = doc\n",
    "                    return paragraph_index \n",
    "                print(doc._.paragraph_index, i, span.text, span.label_)\n",
    "paragraph_index = run()\n",
    "paragraph_index, target_span, target_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, None, None)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 他,\n",
       " 〔記者鍾麗華／台北報導〕行政院長蘇貞昌今天（12日）接見立陶宛國會國安及國防事務議員訪團，他致詞時表示，中國的威權擴張毫無道理且蠻橫，台灣應與立陶宛加強合作，一起努力對抗集權擴張行為。)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_span = None\n",
    "target_doc = None\n",
    "def run():\n",
    "    for paragraph_index, doc in enumerate(doc3):\n",
    "        if 'opinion_found' in doc.spans:\n",
    "            for i, span in enumerate(doc.spans['opinion_found']):\n",
    "                if span.text == \"他\":\n",
    "                    return paragraph_index, span, doc\n",
    "                if(span.label_ == \"OPINION_SRC_found\"):\n",
    "                    print(i, span.text, span.label_, [t.pos_ for t in span], check_SRC_type(span))\n",
    "\n",
    "paragraph_index, target_span, target_doc = run()\n",
    "paragraph_index, target_span, target_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span_type ('PRON', '他')\n",
      "span_type[0] PRON\n"
     ]
    }
   ],
   "source": [
    "find_pronoun_resolution(target_doc, paragraph_index, target_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 0 他 OPINION_SRC_found\n",
      "None 1 表示 OPINION_OPR_found\n",
      "None 2 中國的威權擴張毫無道理且蠻橫 OPINION_SEG_found\n",
      "None 3 ，台灣應與立陶宛加強合作，一起努力對抗集權擴張行為 OPINION_SEG_found\n",
      "None 0 蘇揆 OPINION_SRC_found\n",
      "None 1 強調 OPINION_OPR_found\n",
      "None 2 立陶宛與台灣都在威權擴張侵略的最前線，兩國同樣堅持自由、民主，有相同的價值 OPINION_SEG_found\n",
      "None 0 蘇揆 OPINION_SRC_found\n",
      "None 1 指出 OPINION_OPR_found\n",
      "None 2 威權擴張侵略時常違反世界期待，如俄羅斯侵略烏克蘭，透過武力遂行擴張目的，除讓民眾變成難民，也影響整個世界的經濟活動；而中國對台灣的軍事騷擾及各種假訊息滲透，也都是違背世界期待、侵擾區域和平 OPINION_SEG_found\n",
      "None 0 卡斯楚那斯 OPINION_SRC_found\n",
      "None 1 表示 OPINION_OPR_found\n",
      "None 2 ，這次與台灣官員、智庫交流有個共識，就是國防不能只靠軍隊，應該要靠社會一起執行全民國防 OPINION_SEG_found\n",
      "None 3 ，他也願意分享立陶宛的經驗 OPINION_SEG_found\n",
      "None 0 立陶宛國會友台小組副主席莎卡琳恩 OPINION_SRC_found\n",
      "None 1 指出 OPINION_OPR_found\n",
      "None 2 台灣與立陶宛都距離敵人很近 OPINION_SEG_found\n",
      "None 3 這同時是威脅也是優勢 OPINION_SEG_found\n",
      "None 4 立陶宛 OPINION_SRC_found\n",
      "None 5 倡導 OPINION_OPR_found\n",
      "None 6 如同俄羅斯侵略烏克蘭一樣 OPINION_SEG_found\n"
     ]
    }
   ],
   "source": [
    "for doc in doc3:\n",
    "    if 'opinion_found' in doc.spans:\n",
    "        for i, span in enumerate(doc.spans['opinion_found']):\n",
    "            # if span.text == \"他\":\n",
    "            #     target_span = span\n",
    "            #     target_doc = doc\n",
    "            #     break\n",
    "            print(doc._.paragraph_index, i, span.text, span.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_doc\n",
    "target_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-opinion-label-7mK3qE6W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
