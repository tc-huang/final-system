{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colab\n",
    "# !pip install spacy_stanza\n",
    "# !pip install ckip_transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import pathlib\n",
    "import sys\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Spacy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_pipeline_parent_path = pathlib.Path.cwd().parent.parent.parent.parent\n",
    "sys.path.append(str(spacy_pipeline_parent_path))\n",
    "\n",
    "from spacy_pipeline import pipeline_setup\n",
    "from spacy_pipeline import opinion_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"opinion_v0\": {\n",
    "        \"version\": \"opinion_v0\",\n",
    "        \"pattern\": [\n",
    "            {\n",
    "                \"RIGHT_ID\": \"OPINION_OPR_found_root\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"TAG\": {\n",
    "                        \"IN\": [\"VE\"]\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"OPINION_OPR_found_root\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": \"OPINION_SRC_found_root\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": {\n",
    "                        \"IN\": [\"nsubj\"]\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"OPINION_OPR_found_root\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": \"OPINION_SEG_found_root\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": {\n",
    "                        \"IN\": [\"ccomp\", \"parataxis\"]\n",
    "                    },\n",
    "                    # \"POS\": {\n",
    "                    #         \"IN\": [\"VERB\", \"NOUN\", \"ADJ\"]\n",
    "                    # }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 07:02:05 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76009bab56e4d35a39a88e52b0601d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 07:02:06 INFO: Loading these models for language: zh-hant (Traditional_Chinese):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-03-28 07:02:06 INFO: Using device: cpu\n",
      "2023-03-28 07:02:07 INFO: Loading: tokenize\n",
      "2023-03-28 07:02:07 INFO: Loading: pos\n",
      "2023-03-28 07:02:07 INFO: Loading: lemma\n",
      "2023-03-28 07:02:07 INFO: Loading: depparse\n",
      "2023-03-28 07:02:07 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opinion_matcher']\n",
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns   Requires   Scores   Retokenizes\n",
      "-   ---------------   -------   --------   ------   -----------\n",
      "0   opinion_matcher                                 False      \n",
      "\n",
      "\u001b[38;5;2m✔ No problems found.\u001b[0m\n",
      "{'summary': {'opinion_matcher': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}}, 'problems': {'opinion_matcher': []}, 'attrs': {}}\n"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline_setup.get_opinion_pipeline(methods['opinion_v0'])\n",
    "vocab = pipeline.vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_work_flow(all_docs, spacy_pipeline, n_process=1):\n",
    "    \n",
    "    # try:\n",
    "    with tqdm(total=len(all_docs)) as pbar:\n",
    "        \n",
    "        for paragraphs in all_docs:\n",
    "                \n",
    "            for i, doc in enumerate(spacy_pipeline.pipe(paragraphs, n_process=n_process)):\n",
    "                pass\n",
    "            pbar.update(1)\n",
    "    return all_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca842083c6114d4d880a43ffe661e240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pickle_dir = str(pathlib.Path.cwd().parent)\n",
    "pickle_file = 'label_news_200_docs_stanza.pkl'\n",
    "\n",
    "with open(pickle_dir + '/' + pickle_file, 'rb') as f:\n",
    "    bytes_data = pickle.load(f)\n",
    "    all_docs_dev = [[Doc(vocab).from_bytes(doc_bytes) for doc_bytes in docs] for docs in bytes_data]\n",
    "\n",
    "all_docs_dev = run_work_flow(all_docs_dev, pipeline, n_process=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all_docs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4b9f06f87f4186a830751420810d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pickle_dir = str(pathlib.Path.cwd().parent)\n",
    "pickle_file = 'label_news_50_test_docs_stanza.pkl'\n",
    "\n",
    "with open(pickle_dir + '/' + pickle_file, 'rb') as f:\n",
    "    bytes_data = pickle.load(f)\n",
    "    all_docs_test = [[Doc(vocab).from_bytes(doc_bytes) for doc_bytes in docs] for docs in bytes_data]\n",
    "\n",
    "all_docs_test = run_work_flow(all_docs_test, pipeline, n_process=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# span level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def get_recall(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def get_f_score(precision, recall, beta=1):\n",
    "    return (1 + beta**2) * precision * recall / (beta**2 * precision + recall)\n",
    "\n",
    "label_match_dict = {\n",
    "    \"OPINION_SRC\": \"OPINION_SRC_found\",\n",
    "    \"OPINION_OPR\": \"OPINION_OPR_found\",\n",
    "    \"OPINION_SEG\": \"OPINION_SEG_found\" \n",
    "}\n",
    "\n",
    "def delete_around_punt_check_span(label_span, match_span):\n",
    "    puct_list = ['，', '。', '「', '」', ' ', '！', '？', ';', ':', \"'\", '\"', '‘', '“', '『', '』', '、', '（', '）']\n",
    "    \n",
    "    while label_span.text[0] in puct_list:\n",
    "        label_span = label_span[1:]\n",
    "\n",
    "    while label_span.text[-1] in puct_list:\n",
    "        label_span = label_span[:-1] \n",
    "    \n",
    "    while match_span.text[0] in puct_list:\n",
    "        match_span = match_span[1:]\n",
    "\n",
    "    while match_span.text[-1] in puct_list:\n",
    "        match_span = match_span[:-1]\n",
    "\n",
    "    \n",
    "    if label_span.start == match_span.start and label_span.end == match_span.end:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def interval_check_span(label_span, match_span):\n",
    "    if label_span.start <= match_span.start and label_span.end >= match_span.end:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def tolerance_check_span(label_span, match_span, tolerance=1):\n",
    "    if abs(label_span.start - match_span.start) <= tolerance and label_span.end == match_span.end:\n",
    "        return True\n",
    "    if label_span.start == match_span.start and abs(label_span.end - match_span.end) <= tolerance:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_eval(all_docs, method):\n",
    "    \n",
    "    counter = {\n",
    "        'OPINION_OPR_FP': 0,\n",
    "        'OPINION_OPR_FN': 0,\n",
    "        'OPINION_OPR_TP': 0,\n",
    "\n",
    "        'OPINION_SRC_FP': 0,\n",
    "        'OPINION_SRC_FN': 0,\n",
    "        'OPINION_SRC_TP': 0,\n",
    "        \n",
    "        'OPINION_SEG_FP': 0,\n",
    "        'OPINION_SEG_FN': 0,\n",
    "        'OPINION_SEG_TP': 0,\n",
    "    }\n",
    "\n",
    "    for docs in all_docs:\n",
    "        for doc in docs:\n",
    "\n",
    "            spans = {\n",
    "                'OPINION_SRC_TP': [],\n",
    "                'OPINION_OPR_TP': [],\n",
    "                'OPINION_SEG_TP': [],\n",
    "\n",
    "                'OPINION_SRC_FP': [],\n",
    "                'OPINION_OPR_FP': [],\n",
    "                'OPINION_SEG_FP': [],\n",
    "\n",
    "                'OPINION_SRC_FN': [],\n",
    "                'OPINION_OPR_FN': [],\n",
    "                'OPINION_SEG_FN': [],\n",
    "            }\n",
    "            \n",
    "            if 'opinion_found' in doc.spans and 'opinion_label' in doc.spans:\n",
    "                for found_span in doc.spans['opinion_found']:\n",
    "                    found_match = False\n",
    "                    for label_span in doc.spans['opinion_label']:\n",
    "                        if method(label_span, found_span) and found_span.label_ == label_match_dict[label_span.label_]:\n",
    "                            spans[f\"{label_span.label_}_TP\"].append(label_span)\n",
    "                            found_match = True\n",
    "                            break\n",
    "                    if not found_match:\n",
    "                        spans[f\"{found_span.label_[:11]}_FP\"].append(found_span)\n",
    "                \n",
    "                for label_span in doc.spans['opinion_label']:\n",
    "                    if label_span not in spans[f\"{label_span.label_}_TP\"]:\n",
    "                        spans[f\"{label_span.label_}_FN\"].append(label_span)\n",
    "\n",
    "            elif 'opinion_found' in doc.spans:\n",
    "                for found_span in doc.spans['opinion_found']:\n",
    "                    spans[f\"{found_span.label_[:11]}_FP\"].append(found_span)\n",
    "\n",
    "            elif 'opinion_label' in doc.spans:\n",
    "                for label_span in doc.spans['opinion_label']:\n",
    "                    spans[f\"{label_span.label_}_FN\"].append(label_span)\n",
    "\n",
    "            for key in counter.keys():\n",
    "                counter[key] += len(spans[key])\n",
    "\n",
    "    return {\n",
    "        'OPINION_SRC': {\n",
    "            'precision': get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']), get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN'])),\n",
    "        },\n",
    "        'OPINION_OPR': {\n",
    "            'precision': get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']),\n",
    "            'recall': get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']), get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN'])),\n",
    "        },\n",
    "        'OPINION_SEG': {\n",
    "            'precision': get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']), get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']))\n",
    "        },\n",
    "        'counter': counter\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OPINION_SRC': {'precision': 0.6675031367628608,\n",
       "  'recall': 0.5368314833501514,\n",
       "  'f_score': 0.5950782997762863},\n",
       " 'OPINION_OPR': {'precision': 0.8181818181818182,\n",
       "  'recall': 0.5982142857142857,\n",
       "  'f_score': 0.6911174785100287},\n",
       " 'OPINION_SEG': {'precision': 0.17697594501718214,\n",
       "  'recall': 0.19452313503305005,\n",
       "  'f_score': 0.18533513270355376},\n",
       " 'counter': {'OPINION_OPR_FP': 134,\n",
       "  'OPINION_OPR_FN': 405,\n",
       "  'OPINION_OPR_TP': 603,\n",
       "  'OPINION_SRC_FP': 265,\n",
       "  'OPINION_SRC_FN': 459,\n",
       "  'OPINION_SRC_TP': 532,\n",
       "  'OPINION_SEG_FP': 958,\n",
       "  'OPINION_SEG_FN': 853,\n",
       "  'OPINION_SEG_TP': 206}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eval(all_docs_dev, delete_around_punt_check_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OPINION_SRC': {'precision': 0.7064676616915423,\n",
       "  'recall': 0.5657370517928287,\n",
       "  'f_score': 0.6283185840707964},\n",
       " 'OPINION_OPR': {'precision': 0.8315789473684211,\n",
       "  'recall': 0.6220472440944882,\n",
       "  'f_score': 0.7117117117117117},\n",
       " 'OPINION_SEG': {'precision': 0.1282051282051282,\n",
       "  'recall': 0.13559322033898305,\n",
       "  'f_score': 0.13179571663920922},\n",
       " 'counter': {'OPINION_OPR_FP': 32,\n",
       "  'OPINION_OPR_FN': 96,\n",
       "  'OPINION_OPR_TP': 158,\n",
       "  'OPINION_SRC_FP': 59,\n",
       "  'OPINION_SRC_FN': 109,\n",
       "  'OPINION_SRC_TP': 142,\n",
       "  'OPINION_SEG_FP': 272,\n",
       "  'OPINION_SEG_FN': 255,\n",
       "  'OPINION_SEG_TP': 40}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eval(all_docs_test, delete_around_punt_check_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_eval(all_docs_dev, delete_around_punt_check_span)\n",
    "# new_eval(all_docs, interval_check)\n",
    "# new_eval(all_docs, tolerance_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_eval(all_docs_test, delete_around_punt_check_span)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# token level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_token_level(all_docs):\n",
    "\n",
    "    counter = {\n",
    "        'OPINION_SRC_FP': 0,\n",
    "        'OPINION_OPR_FP': 0,\n",
    "        'OPINION_SEG_FP': 0,\n",
    "\n",
    "        'OPINION_SRC_FN': 0,\n",
    "        'OPINION_OPR_FN': 0,\n",
    "        'OPINION_SEG_FN': 0,\n",
    "        \n",
    "        'OPINION_SRC_TP': 0,\n",
    "        'OPINION_OPR_TP': 0,\n",
    "        'OPINION_SEG_TP': 0,\n",
    "    }\n",
    "\n",
    "    for docs in all_docs:\n",
    "        for doc in docs:\n",
    "            \n",
    "            if 'opinion_found' in doc.spans and 'opinion_label' in doc.spans:\n",
    "                for token in doc:\n",
    "                    if token._.found_type == \"OPINION_SRC_found\":\n",
    "                        if \"OPINION_SRC\" in token._.label_type:\n",
    "                            counter['OPINION_SRC_TP'] += 1\n",
    "                        else:\n",
    "                            counter['OPINION_SRC_FP'] += 1\n",
    "                    elif token._.found_type == \"OPINION_OPR_found\":\n",
    "                        if \"OPINION_OPR\" in token._.label_type:\n",
    "                            counter['OPINION_OPR_TP'] += 1\n",
    "                        else:\n",
    "                            counter['OPINION_OPR_FP'] += 1\n",
    "                    elif token._.found_type == \"OPINION_SEG_found\":\n",
    "                        if \"OPINION_SEG\" in token._.label_type:\n",
    "                            counter['OPINION_SEG_TP'] += 1\n",
    "                        else:\n",
    "                            counter['OPINION_SEG_FP'] += 1\n",
    "                \n",
    "                for token in doc:\n",
    "                    if \"OPINION_SRC\" in token._.label_type and token._.found_type != \"OPINION_SRC_found\":\n",
    "                        counter['OPINION_SRC_FN'] += 1\n",
    "                    elif \"OPINION_OPR\" in token._.label_type and token._.found_type != \"OPINION_OPR_found\":\n",
    "                        counter['OPINION_OPR_FN'] += 1\n",
    "                    elif \"OPINION_SEG\" in token._.label_type and token._.found_type != \"OPINION_SEG_found\":\n",
    "                        counter['OPINION_SEG_FN'] += 1\n",
    "\n",
    "    return {\n",
    "        'OPINION_SRC': {\n",
    "            'precision': get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FP']), get_recall(counter['OPINION_SRC_TP'], counter['OPINION_SRC_FN'])),\n",
    "        },\n",
    "        'OPINION_OPR': {\n",
    "            'precision': get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']),\n",
    "            'recall': get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FP']), get_recall(counter['OPINION_OPR_TP'], counter['OPINION_OPR_FN'])),\n",
    "        },\n",
    "        'OPINION_SEG': {\n",
    "            'precision': get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']),\n",
    "            'recall': get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']),\n",
    "            'f_score': get_f_score(get_precision(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FP']), get_recall(counter['OPINION_SEG_TP'], counter['OPINION_SEG_FN']))\n",
    "        },\n",
    "        'counter': counter\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OPINION_SRC': {'precision': 0.765869365225391,\n",
       "  'recall': 0.6141645149391368,\n",
       "  'f_score': 0.6816786079836233},\n",
       " 'OPINION_OPR': {'precision': 0.8300395256916996,\n",
       "  'recall': 0.6140350877192983,\n",
       "  'f_score': 0.7058823529411765},\n",
       " 'OPINION_SEG': {'precision': 0.9651360237002782,\n",
       "  'recall': 0.5670197185490204,\n",
       "  'f_score': 0.7143544764145897},\n",
       " 'counter': {'OPINION_SRC_FP': 509,\n",
       "  'OPINION_OPR_FP': 129,\n",
       "  'OPINION_SEG_FP': 965,\n",
       "  'OPINION_SRC_FN': 1046,\n",
       "  'OPINION_OPR_FN': 396,\n",
       "  'OPINION_SEG_FN': 20399,\n",
       "  'OPINION_SRC_TP': 1665,\n",
       "  'OPINION_OPR_TP': 630,\n",
       "  'OPINION_SEG_TP': 26714}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_token_level(all_docs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OPINION_SRC': {'precision': 0.7693693693693694,\n",
       "  'recall': 0.5670650730411687,\n",
       "  'f_score': 0.6529051987767585},\n",
       " 'OPINION_OPR': {'precision': 0.8473684210526315,\n",
       "  'recall': 0.6145038167938931,\n",
       "  'f_score': 0.7123893805309733},\n",
       " 'OPINION_SEG': {'precision': 0.9812138728323699,\n",
       "  'recall': 0.5566030002459218,\n",
       "  'f_score': 0.7102881949892776},\n",
       " 'counter': {'OPINION_SRC_FP': 128,\n",
       "  'OPINION_OPR_FP': 29,\n",
       "  'OPINION_SEG_FP': 130,\n",
       "  'OPINION_SRC_FN': 326,\n",
       "  'OPINION_OPR_FN': 101,\n",
       "  'OPINION_SEG_FN': 5409,\n",
       "  'OPINION_SRC_TP': 427,\n",
       "  'OPINION_OPR_TP': 161,\n",
       "  'OPINION_SEG_TP': 6790}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_token_level(all_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_token_level(all_docs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_token_level(all_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(民進黨, 范雲, 民進黨, 台南, 黃偉哲, 今天)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs_dev[0][0].ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "民進黨 ORG 0 2\n",
      "范雲 PERSON 3 4\n",
      "民進黨 ORG 30 32\n",
      "台南 GPE 35 36\n",
      "黃偉哲 PERSON 37 40\n",
      "今天 DATE 40 41\n"
     ]
    }
   ],
   "source": [
    "for ent in all_docs_dev[0][0].ents:\n",
    "    print(ent, ent.label_, ent.start, ent.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = all_docs_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[范雲, 黃偉哲], [黃偉哲, 范雲, 范雲], [范雲, 黃偉哲, 黃偉哲]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_list_list = []\n",
    "\n",
    "for doc in docs:\n",
    "    ent_list = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    ent_list_list.append(ent_list)\n",
    "\n",
    "ent_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-opinion-label-7mK3qE6W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
